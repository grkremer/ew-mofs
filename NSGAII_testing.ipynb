{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc6024c-9afe-4017-9c7b-f1eb18df47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PYMOO\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.operators.sampling.rnd import BinaryRandomSampling\n",
    "from pymoo.operators.crossover.pntx import TwoPointCrossover\n",
    "from pymoo.operators.mutation.bitflip import BitflipMutation\n",
    "from pymoo.core.sampling import Sampling\n",
    "from pymoo.core.mutation import Mutation\n",
    "\n",
    "#multiprocessamento e pymoo\n",
    "import os\n",
    "import multiprocessing\n",
    "from pymoo.core.problem import StarmapParallelization\n",
    "\n",
    "#Pandas, SKLearn e etc.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import plotly.express as px\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605001c8-3000-4897-ae41-63af136c0825",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('Data/data_normalized.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e62507b-cb41-4613-bf52-66efa3b63df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = list(data.columns)\n",
    "colunas.remove('samples')\n",
    "colunas.remove('type')\n",
    "\n",
    "X = data[colunas]\n",
    "y = data['type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb3d728-0613-45d1-bec8-36cc4bde74ab",
   "metadata": {},
   "source": [
    "Funções de Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a3fc854-36ff-4bc7-9fe0-72f1cbcc5e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_worker():\n",
    "    global pid_, X_worker, y_worker, colunas_worker\n",
    "    pid_ = os.getpid()\n",
    "    X_worker = X.copy()\n",
    "    y_worker = y.copy()\n",
    "    colunas_worker = colunas.copy()\n",
    "    print(pid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a55f701-e8ea-4a71-9d66-c93d5a8a6f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneSelection(ElementwiseProblem):\n",
    "    def __init__(self, X, y, runner):\n",
    "        #self.X = X_worker\n",
    "        #self.y = y_worker\n",
    "        self.n_features = X.shape[1]\n",
    "        self.eval_dict = {'n_features':[], 'f1_score':[]}\n",
    "        super().__init__(   n_var=self.n_features,\n",
    "    \t\t\t\t\t\tn_obj=2,\n",
    "    \t\t\t\t\t\tn_constr=0,\n",
    "    \t\t\t\t\t\txl=np.zeros(self.n_features),\n",
    "    \t\t\t\t\t\txu=np.ones(self.n_features),\n",
    "    \t\t\t\t\t\telementwise_evaluation=True,\n",
    "                            type_var=bool,\n",
    "                            save_history=True,\n",
    "                            elementwise_runner=runner)\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "    \t# seleciona as features de acordo com o vetor binário\n",
    "        selected_features = np.where(x == 1)[-1]\n",
    "        X_selected = X_worker.iloc[:,selected_features]\n",
    "    \t\n",
    "        # Kfolding usado para separar em treino e teste\n",
    "        skf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "        #X_train, X_valid, y_train, y_valid = train_test_split(X_selected, self.y, test_size=0.1, random_state=100)\n",
    "    \t\n",
    "    \t# treino usando modelo SVM\n",
    "        clf = svm.SVC(kernel='linear')\n",
    "\n",
    "        # compute f_1 and AUC on validation set\n",
    "        f_1 = np.mean(cross_val_score(clf, X_selected, y_worker, cv=skf, scoring='f1_macro'))\n",
    "        n_features = len(selected_features)\n",
    "        # salvar os resultados\n",
    "        self.eval_dict['n_features'].append(n_features)\n",
    "        self.eval_dict['f1_score'].append(f_1)\n",
    "    \t\n",
    "    \t# define os objetivos a serem minimizados\n",
    "        out[\"F\"] = [n_features, -f_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a12a421-ee29-4d77-b3d5-d9e3f30f89a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDistributedRandomSampling(Sampling):\n",
    "\n",
    "    def _do(self, problem, n_samples, **kwargs):\n",
    "        population = []\n",
    "        max = 1000\n",
    "        ns = []\n",
    "        for i in range(n_samples):\n",
    "            trues = np.random.randint(1, max + 1)\n",
    "            individual = np.array([True] * trues + [False] * (problem.n_var - trues))\n",
    "            np.random.shuffle(individual)\n",
    "            population.append(individual)\n",
    "            ns.append((individual.sum()))\n",
    "        #print(population)\n",
    "        print(sorted(ns))\n",
    "        return population\n",
    "\n",
    "class BitflipMutation(Mutation):\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "        prob_var = self.get_prob_var(problem, size=(len(X), 1))\n",
    "        Xp = np.copy(X)\n",
    "        flip = np.random.random(X.shape) < prob_var\n",
    "        Xp[flip] = ~X[flip]\n",
    "        return Xp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e62f5b4-7d8d-41a5-8485-55b97fe08e78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2556425567\n",
      "\n",
      "2556225563\n",
      "\n",
      "25573\n",
      "2556625575\n",
      "\n",
      "25561\n",
      "25565\n",
      "25569\n",
      "25571\n",
      "25568\n",
      "25579\n",
      "2557225570\n",
      "\n",
      "25577\n",
      "25574\n",
      "25576\n",
      "25580\n",
      "25578\n",
      "25581\n",
      "25589\n",
      "25584\n",
      "25587\n",
      "25594\n",
      "25582\n",
      "25585\n",
      "25598\n",
      "25586\n",
      "25591\n",
      "25600\n",
      "25596\n",
      "25588\n",
      "25590\n",
      "25602\n",
      "25595\n",
      "2559925606\n",
      "\n",
      "25597\n",
      "2560325611\n",
      "\n",
      "25605\n",
      "2560125592\n",
      "\n",
      "25604\n",
      "25593\n",
      "25623\n",
      "25618\n"
     ]
    }
   ],
   "source": [
    "# initialize the thread pool and create the runner\n",
    "n_proccess = 48\n",
    "pool = multiprocessing.Pool(n_proccess, initializer=_init_worker)\n",
    "runner = StarmapParallelization(pool.starmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc05b07-edaa-45ac-a583-60abc1b3bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = GeneSelection(X,y.copy().values, runner)\n",
    "algorithm = NSGA2(pop_size=96,\n",
    "\t\t\t\t  sampling=BinaryDistributedRandomSampling(),\n",
    "\t\t\t\t  crossover=TwoPointCrossover(),\n",
    "\t\t\t\t  mutation=BitflipMutation(),\n",
    "                  save_history = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44ed68e6-515f-4baa-b5a7-507617256416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 7, 19, 44, 80, 106, 115, 135, 138, 172, 180, 180, 191, 203, 214, 233, 236, 251, 263, 267, 272, 275, 302, 323, 329, 335, 339, 347, 352, 353, 354, 359, 364, 367, 377, 387, 395, 418, 418, 427, 433, 443, 444, 452, 460, 519, 520, 525, 559, 564, 580, 593, 596, 619, 630, 630, 634, 651, 653, 663, 664, 679, 692, 696, 705, 706, 724, 734, 776, 797, 811, 814, 815, 816, 823, 836, 848, 852, 854, 881, 882, 893, 900, 916, 920, 926, 928, 950, 951, 953, 965, 979, 985, 991, 991, 995]\n",
      "==========================================================\n",
      "n_gen  |  n_eval  | n_nds  |      eps      |   indicator  \n",
      "==========================================================\n",
      "     1 |       96 |      9 |             - |             -\n",
      "     2 |      192 |     12 |  0.0119947605 |         ideal\n",
      "     3 |      288 |     11 |  0.0110075954 |             f\n",
      "     4 |      384 |     16 |  2.1284046693 |         nadir\n",
      "     5 |      480 |     17 |  0.0275174526 |             f\n",
      "     6 |      576 |     21 |  0.0236300354 |             f\n",
      "     7 |      672 |     19 |  0.3627602979 |         nadir\n",
      "     8 |      768 |     18 |  0.0078431373 |         nadir\n",
      "     9 |      864 |     14 |  0.1184210526 |         nadir\n",
      "    10 |      960 |     14 |  0.0192690006 |         ideal\n",
      "    11 |     1056 |     16 |  0.0038910506 |         ideal\n",
      "    12 |     1152 |     10 |  0.0210148936 |             f\n",
      "    13 |     1248 |     12 |  0.0202965189 |             f\n",
      "    14 |     1344 |     12 |  0.2355769231 |         nadir\n",
      "    15 |     1440 |     12 |  0.1122994652 |         nadir\n",
      "    16 |     1536 |     11 |  0.0128205128 |         ideal\n",
      "    17 |     1632 |     10 |  0.0107539494 |             f\n",
      "    18 |     1728 |     13 |  0.0088981099 |             f\n",
      "    19 |     1824 |     13 |  0.0046477893 |             f\n",
      "    20 |     1920 |     12 |  0.0260078947 |         ideal\n",
      "    21 |     2016 |     14 |  0.0015951231 |             f\n",
      "    22 |     2112 |     13 |  0.0277777778 |         nadir\n",
      "    23 |     2208 |     15 |  0.0061909949 |             f\n",
      "    24 |     2304 |     15 |  0.4025974026 |         nadir\n",
      "    25 |     2400 |     15 |  0.0054394543 |             f\n",
      "    26 |     2496 |     15 |  0.000000E+00 |             f\n",
      "    27 |     2592 |     15 |  0.0013995557 |             f\n",
      "    28 |     2688 |     16 |  0.0013120835 |             f\n",
      "    29 |     2784 |     15 |  0.0240466743 |             f\n",
      "    30 |     2880 |     14 |  0.0010364036 |             f\n",
      "    31 |     2976 |     13 |  0.0065355945 |             f\n",
      "    32 |     3072 |     14 |  0.0009437766 |             f\n",
      "    33 |     3168 |     11 |  0.5092012368 |         nadir\n",
      "    34 |     3264 |     13 |  0.0113529744 |             f\n",
      "    35 |     3360 |     14 |  0.0014613908 |             f\n",
      "    36 |     3456 |     15 |  0.0018025658 |             f\n",
      "    37 |     3552 |     16 |  0.0065359477 |         ideal\n",
      "    38 |     3648 |     16 |  0.0007191656 |             f\n",
      "    39 |     3744 |     16 |  0.0007191656 |             f\n",
      "    40 |     3840 |     13 |  0.0017468070 |             f\n",
      "    41 |     3936 |     12 |  0.0022786396 |             f\n",
      "    42 |     4032 |     13 |  0.0048963961 |             f\n",
      "    43 |     4128 |     13 |  0.0089603549 |         ideal\n",
      "    44 |     4224 |     13 |  0.0294117647 |         nadir\n",
      "    45 |     4320 |     13 |  0.000000E+00 |             f\n",
      "    46 |     4416 |     13 |  0.000000E+00 |             f\n",
      "    47 |     4512 |     14 |  0.0010504277 |             f\n",
      "    48 |     4608 |     15 |  0.0239778542 |             f\n",
      "    49 |     4704 |     17 |  0.0028846859 |             f\n",
      "    50 |     4800 |     16 |  0.0016345285 |             f\n",
      "    51 |     4896 |     15 |  0.0149253731 |         nadir\n",
      "    52 |     4992 |     15 |  0.000000E+00 |             f\n",
      "    53 |     5088 |     15 |  0.0009951636 |             f\n",
      "    54 |     5184 |     16 |  0.0945945946 |         nadir\n",
      "    55 |     5280 |     16 |  0.0000165173 |             f\n",
      "    56 |     5376 |     16 |  0.0052442455 |             f\n",
      "    57 |     5472 |     17 |  0.0088781987 |         ideal\n",
      "    58 |     5568 |     16 |  0.0019053745 |             f\n",
      "    59 |     5664 |     16 |  0.0035754797 |             f\n",
      "    60 |     5760 |     15 |  0.0018749211 |             f\n",
      "    61 |     5856 |     11 |  6.3984444496 |         nadir\n",
      "    62 |     5952 |     11 |  0.000000E+00 |             f\n",
      "    63 |     6048 |     10 |  0.0156905792 |             f\n",
      "    64 |     6144 |     11 |  0.000000E+00 |             f\n",
      "    65 |     6240 |     11 |  0.0135135135 |         nadir\n",
      "    66 |     6336 |     11 |  0.000000E+00 |             f\n",
      "    67 |     6432 |     11 |  0.000000E+00 |             f\n",
      "    68 |     6528 |     12 |  0.0078489174 |             f\n",
      "    69 |     6624 |     12 |  0.000000E+00 |             f\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 190, in fit\n    X, y = self._validate_data(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 622, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1146, in check_X_y\n    X = check_array(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 795, in check_array\n    dtype_orig = np.result_type(*dtypes_orig)\n  File \"<__array_function__ internals>\", line 200, in result_type\nValueError: at least one array or dtype is required\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n  File \"/home/grkremer/.local/lib/python3.10/site-packages/pymoo/core/problem.py\", line 25, in __call__\n    self.problem._evaluate(x, out, *self.args, **self.kwargs)\n  File \"/tmp/ipykernel_25447/3482785397.py\", line 30, in _evaluate\n    f_1 = np.mean(cross_val_score(clf, X_selected, y_worker, cv=skf, scoring='f1_macro'))\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 562, in cross_val_score\n    cv_results = cross_validate(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 328, in cross_validate\n    _warn_or_raise_about_fit_failures(results, error_score)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 414, in _warn_or_raise_about_fit_failures\n    raise ValueError(all_fits_failed_message)\nValueError: \nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 190, in fit\n    X, y = self._validate_data(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 622, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1146, in check_X_y\n    X = check_array(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 795, in check_array\n    dtype_orig = np.result_type(*dtypes_orig)\n  File \"<__array_function__ internals>\", line 200, in result_type\nValueError: at least one array or dtype is required\n\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# problem class\u001b[39;49;00m\n\u001b[1;32m      2\u001b[0m \u001b[43m\t\t\t    \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# NSGA2 algorithm\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_gen\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# number of iteration for eval problem class\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m\t\t\t    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pymoo/optimize.py:67\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(problem, algorithm, termination, copy_algorithm, copy_termination, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m     algorithm\u001b[38;5;241m.\u001b[39msetup(problem, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# actually execute the algorithm\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# store the deep copied algorithm in the result object\u001b[39;00m\n\u001b[1;32m     70\u001b[0m res\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m=\u001b[39m algorithm\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pymoo/core/algorithm.py:138\u001b[0m, in \u001b[0;36mAlgorithm.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_next():\n\u001b[0;32m--> 138\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pymoo/core/algorithm.py:158\u001b[0m, in \u001b[0;36mAlgorithm.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# call the advance with them after evaluation\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m infills \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfills\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(infills\u001b[38;5;241m=\u001b[39minfills)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# if the algorithm does not follow the infill-advance scheme just call advance\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pymoo/core/evaluator.py:69\u001b[0m, in \u001b[0;36mEvaluator.eval\u001b[0;34m(self, problem, pop, skip_already_evaluated, evaluate_values_of, count_evals, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# evaluate the solutions (if there are any)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(I) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# do the actual evaluation - call the sub-function to set the corresponding values to the population\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop\u001b[49m\u001b[43m[\u001b[49m\u001b[43mI\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_values_of\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# update the function evaluation counter\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count_evals:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pymoo/core/evaluator.py:90\u001b[0m, in \u001b[0;36mEvaluator._eval\u001b[0;34m(self, problem, pop, evaluate_values_of, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m X \u001b[38;5;241m=\u001b[39m pop\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# call the problem to evaluate the solutions\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mproblem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_values_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluate_values_of\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_as_dictionary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# for each of the attributes set it to the problem\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m out\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pymoo/core/problem.py:257\u001b[0m, in \u001b[0;36mProblem.evaluate\u001b[0;34m(self, X, return_values_of, return_as_dictionary, *args, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m     only_single_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, np\u001b[38;5;241m.\u001b[39mndarray))\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# this is where the actual evaluation takes place\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m _out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_values_of\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m out \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _out\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    261\u001b[0m \n\u001b[1;32m    262\u001b[0m     \u001b[38;5;66;03m# copy it to a numpy array (it might be one of jax at this point)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pymoo/core/problem.py:297\u001b[0m, in \u001b[0;36mProblem.do\u001b[0;34m(self, X, return_values_of, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# do the function evaluation\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melementwise:\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_elementwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_vectorized(X, out, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pymoo/core/problem.py:315\u001b[0m, in \u001b[0;36mProblem._evaluate_elementwise\u001b[0;34m(self, X, out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melementwise_func(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# execute the runner\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m elems \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melementwise_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# for each evaluation call\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m elems:\n\u001b[1;32m    319\u001b[0m \n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# for each key stored for this evaluation\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pymoo/core/problem.py:42\u001b[0m, in \u001b[0;36mStarmapParallelization.__call__\u001b[0;34m(self, f, X)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, X):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m job, i, func, args, kwds \u001b[38;5;241m=\u001b[39m task\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:51\u001b[0m, in \u001b[0;36mstarmapstar\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmapstar\u001b[39m(args):\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mstarmap(args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pymoo/core/problem.py:25\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     24\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem\u001b[38;5;241m.\u001b[39m_evaluate(x, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m, in \u001b[0;36m_evaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m clf \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mSVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# compute f_1 and AUC on validation set\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m f_1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(cross_val_score(clf, X_selected, y_worker, cv\u001b[38;5;241m=\u001b[39mskf, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_macro\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     31\u001b[0m n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(selected_features)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# salvar os resultados\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m()\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[1;32m    563\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    564\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    565\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    566\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m    567\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[1;32m    568\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m    569\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    570\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    571\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[1;32m    572\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[1;32m    573\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    574\u001b[0m )\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:328\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m    309\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    311\u001b[0m         clone(estimator),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    326\u001b[0m )\n\u001b[0;32m--> 328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m()\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 190, in fit\n    X, y = self._validate_data(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 622, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1146, in check_X_y\n    X = check_array(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 795, in check_array\n    dtype_orig = np.result_type(*dtypes_orig)\n  File \"<__array_function__ internals>\", line 200, in result_type\nValueError: at least one array or dtype is required\n"
     ]
    }
   ],
   "source": [
    "res = minimize(problem,  # problem class\n",
    "\t\t\t    algorithm,  # NSGA2 algorithm\n",
    "                (\"n_gen\", 500), # number of iteration for eval problem class\n",
    "\t\t\t    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1cd1a0-3f0b-4e68-929c-297805141afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_evals = np.array([e.evaluator.n_eval for e in res.history])\n",
    "opt = np.array([e.opt[0].F for e in res.history])\n",
    "\n",
    "X_res, F_res = res.opt.get(\"X\", \"F\")\n",
    "\n",
    "hist = res.history\n",
    "print(len(hist))\n",
    "n_evals = []             # corresponding number of function evaluations\\\n",
    "hist_F = []              # the objective space values in each generation\n",
    "hist_cv = []             # constraint violation in each generation\n",
    "hist_cv_avg = []         # average constraint violation in the whole population\n",
    "\n",
    "for algo in hist:\n",
    "\n",
    "    # store the number of function evaluations\n",
    "    n_evals.append(algo.evaluator.n_eval)\n",
    "\n",
    "    # retrieve the optimum from the algorithm\n",
    "    opt = algo.opt\n",
    "\n",
    "    # store the least contraint violation and the average in each population\n",
    "    hist_cv.append(opt.get(\"CV\").min())\n",
    "    hist_cv_avg.append(algo.pop.get(\"CV\").mean())\n",
    "\n",
    "    # filter out only the feasible and append and objective space values\n",
    "    feas = np.where(opt.get(\"feasible\"))[0]\n",
    "    hist_F.append(opt.get(\"F\")[feas])\n",
    "approx_ideal = F_res.min(axis=0)\n",
    "approx_nadir = F_res.max(axis=0)\n",
    "from pymoo.indicators.hv import Hypervolume\n",
    "\n",
    "metric = Hypervolume(ref_point= np.array([1.1, 1.1]),\n",
    "                     norm_ref_point=False,\n",
    "                     zero_to_one=True,\n",
    "                     ideal=approx_ideal,\n",
    "                     nadir=approx_nadir)\n",
    "\n",
    "hv = [metric.do(_F) for _F in hist_F]\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(n_evals, hv,  color='black', lw=0.7, label=\"Avg. CV of Pop\")\n",
    "plt.scatter(n_evals, hv,  facecolor=\"none\", edgecolor='black', marker=\"p\")\n",
    "plt.title(\"Convergence\")\n",
    "plt.xlabel(\"Function Evaluations\")\n",
    "plt.ylabel(\"Hypervolume\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9db3ae-8a19-4ef6-a263-2a6e52f90313",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(F_res[:, 0], F_res[:, 1], s=30, facecolors='none', edgecolors='blue')\n",
    "plt.title(\"Objective Space\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c0938-d210-4a2f-997d-9a0bc4da2c64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
